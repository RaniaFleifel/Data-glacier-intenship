{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import calendar\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('dff_old.csv')\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names are ['quaretrly', 'Metadata', 'monthly', 'daily']\n"
     ]
    }
   ],
   "source": [
    "#IMPUTING economic indicators \n",
    "\n",
    "xls = pd.ExcelFile('toappend2.xlsx')\n",
    "print('Sheet names are',xls.sheet_names)\n",
    "\n",
    "# to read just one sheet to dataframe:\n",
    "df30_ = pd.read_excel('toappend2.xlsx', sheet_name=\"daily\")\n",
    "#display(df30_)\n",
    "\n",
    "df30_[\"day\"] = df30_['Date'].map(lambda x: x.day)\n",
    "df30_[\"month\"] = df30_['Date'].map(lambda x: x.month)\n",
    "df30_[\"month\"] = df30_[\"month\"].apply(lambda x: calendar.month_abbr[x].lower())\n",
    "df30_[\"year\"] = df30_['Date'].map(lambda x: x.year)\n",
    "df30= df30_.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "df['euribor3m'] = 0.0\n",
    "\n",
    "for i in range(len(df30)):    \n",
    "    i_raw=df30.iloc[i,:]\n",
    "    df.loc[(df.day==i_raw.day) & (df.month==i_raw.month) & (df.year==i_raw.year.astype(float)),'euribor3m']=i_raw.Value\n",
    "\n",
    "df12_ = pd.read_excel('toappend2.xlsx', sheet_name=\"monthly\")\n",
    "#Harmonised index of consumer prices, Consumer confidence indicator\n",
    "\n",
    "df12_.columns\n",
    "df12_.rename(columns={df12_.columns[0]: 'Date', df12_.columns[1]: 'consum_prices_rate',df12_.columns[2]: 'consum_conf_ind'},inplace=True)\n",
    "df12_=df12_.iloc[3:]\n",
    "\n",
    "df12_[\"day\"] = df12_['Date'].map(lambda x: x.day)\n",
    "df12_[\"month\"] = df12_['Date'].map(lambda x: x.month)\n",
    "df12_[\"month\"] = df12_[\"month\"].apply(lambda x: calendar.month_abbr[x].lower())\n",
    "df12_[\"year\"] = df12_['Date'].map(lambda x: x.year)\n",
    "df12= df12_.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "#df12.head()\n",
    "df['consum_prices_rate'] = 0.0\n",
    "df['consum_conf_ind'] = 0.0\n",
    "\n",
    "for i in range(len(df12)):    \n",
    "    i_raw=df12.iloc[i,:]\n",
    "    #print(i,i_raw.Value)\n",
    "    df.loc[(df.day<=i_raw.day) & (df.month==i_raw.month) & (df.year==i_raw.year.astype(float)),'consum_prices_rate']=i_raw.consum_prices_rate\n",
    "    df.loc[(df.day<=i_raw.day) & (df.month==i_raw.month) & (df.year==i_raw.year.astype(float)),'consum_conf_ind']=i_raw.consum_conf_ind    \n",
    "\n",
    "df4_ = pd.read_excel('toappend2.xlsx', sheet_name=\"quaretrly\")\n",
    "\n",
    "df4_.columns\n",
    "df4_.rename(columns={df4_.columns[0]: 'Date', df4_.columns[1]: 'employed',df4_.columns[2]: 'unemployed',df4_.columns[3]: 'unemployed_rate'},inplace=True)\n",
    "df4_=df4_.iloc[3:]\n",
    "\n",
    "df4_[\"month\"] = df4_['Date'].map(lambda x: x.month)\n",
    "df4_[\"month\"] = df4_[\"month\"].apply(lambda x: calendar.month_abbr[x].lower())\n",
    "df4_[\"year\"] = df4_['Date'].map(lambda x: x.year)\n",
    "df4= df4_.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "#display(df4.head())\n",
    "df['employed'] = 0.0\n",
    "df['unemployed'] = 0.0\n",
    "df['unemployed_rate']=0.0\n",
    "\n",
    "for i in range(len(df4)):    \n",
    "    i_raw=df4.iloc[i,:]\n",
    "    #print(i,i_raw.Value)\n",
    "    df.loc[(df.month<=i_raw.month) & (df.year==i_raw.year.astype(float)),'employed']=i_raw.employed\n",
    "    df.loc[(df.month<=i_raw.month) & (df.year==i_raw.year.astype(float)),'unemployed']=i_raw.unemployed\n",
    "    df.loc[(df.month<=i_raw.month) & (df.year==i_raw.year.astype(float)),'unemployed_rate']=i_raw.unemployed_rate    \n",
    "\n",
    "df.to_csv(\"after_append.csv\",\n",
    "          index=False,\n",
    "          encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contingency_table between poutcome and pdays==999:\n",
      "pdays     False   True\n",
      "poutcome              \n",
      "failure    4901      0\n",
      "other      1840      0\n",
      "success    1511      0\n",
      "unknown       5  36954\n"
     ]
    }
   ],
   "source": [
    "# Ambiguous number of entries per feature:\n",
    "# 288 unknowsn in job, 1857 unknowsn in education, 13020 unkowns in contact , 1840 other in poutcome, 36959 unkowns in poutcome\n",
    "\n",
    "# poutcome \n",
    "ct_table_ind=pd.crosstab(df[\"poutcome\"],df[\"pdays\"]==999)\n",
    "print('contingency_table between poutcome and pdays==999:\\n{}'.format(ct_table_ind))\n",
    "#change unknown to nonexistant where pdays==999, ow delete row\n",
    "df.loc[((df['poutcome']=='unknown') & (df[\"pdays\"] == 999)), \"poutcome\"] = 'non_existant'\n",
    "indices_to_drop=df.loc[(df['poutcome']==\"unknown\") & (df['pdays']!=999)].index\n",
    "df.drop(indices_to_drop,axis=0,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "#change pdays=999 to pdays=0 to avoid contributing to outliers \n",
    "df.loc[df[\"pdays\"] == 999, \"pdays\"] = 0\n",
    "df.drop('index',axis=1,inplace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.loc[df.y==\"yes\",'y_equiv']=int(1)\n",
    "df.loc[df.y==\"no\",'y_equiv']=int(0)\n",
    "\n",
    "#flags for \"unknown values\" in https://machinelearningmastery.com/binary-flags-for-missing-values-for-machine-learning/\n",
    "\n",
    "df['contact_missing'] = 0\n",
    "df['poutcome_missing'] = 0\n",
    "df['job_missing'] = 0\n",
    "df['education_missing'] = 0\n",
    "\n",
    "df.loc[df.contact==\"unknown\",'contact_missing']=1\n",
    "df.loc[df.poutcome==\"other\",'poutcome_missing']=1\n",
    "df.loc[df.job==\"unknown\",'job_missing']=1\n",
    "df.loc[df.education==\"unknown\",'education_missing']=1\n",
    "\n",
    "#nominal and cardinal \n",
    "#https://pianalytix.com/how-do-you-handle-missing-values-categorical-data-and-feature-scaling-in-machine-learning/\n",
    "#sefidian.com/2021/07/02/measure-the-correlation-between-numerical-and-categorical-variables-and-the-correlation-between-two-categorical-variables-in-python-chi-square-and-anova/    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins based on train data [20426.4, 40851.8, 61277.200000000004, 81702.6, 102127]\n"
     ]
    }
   ],
   "source": [
    "####################################################### balance \n",
    "df.loc[df[\"balance\"]<0,'overdraft']=1 #this indicates bad credit score so overall not the best candidate to waste time on\n",
    "df.loc[df[\"balance\"]>=0,'overdraft']=0\n",
    "\n",
    "df.loc[df[\"balance\"]<0,'balance']=0 #as if balancerepresent +ve balance only\n",
    "#binning of balance then label_encode\n",
    "#assume5bgroups\n",
    "bins_it=(df.balance.max()-df.balance.min())/5\n",
    "bins=[]#[df.balance.min()]\n",
    "for i in range(1,5):\n",
    "    bins.append(bins_it*i+1)\n",
    "\n",
    "bins.append(df.balance.max())\n",
    "#bins=[bins_middle,df.balance.max()]\n",
    "print('bins based on train data',bins)\n",
    "orig_balance=df['balance']\n",
    "df['balance'] = pd.cut(df['balance'], bins=5, labels=['vlow','low','med','high','vhigh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>consum_conf_ind</th>\n",
       "      <th>employed</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>unemployed_rate</th>\n",
       "      <th>y_equiv</th>\n",
       "      <th>contact_missing</th>\n",
       "      <th>poutcome_missing</th>\n",
       "      <th>job_missing</th>\n",
       "      <th>education_missing</th>\n",
       "      <th>overdraft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>vlow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>4827.7</td>\n",
       "      <td>486.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>vlow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>4827.7</td>\n",
       "      <td>486.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>vlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>4827.7</td>\n",
       "      <td>486.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>vlow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>4827.7</td>\n",
       "      <td>486.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>vlow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>4827.7</td>\n",
       "      <td>486.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default balance housing loan contact  \\\n",
       "0   58    management  married   tertiary       0    vlow       1    0       0   \n",
       "1   44    technician   single  secondary       0    vlow       1    0       0   \n",
       "2   33  entrepreneur  married  secondary       0    vlow       1    1       0   \n",
       "3   47   blue-collar  married    unknown       0    vlow       1    0       0   \n",
       "4   33       unknown   single    unknown       0    vlow       0    0       0   \n",
       "\n",
       "   day  ... consum_conf_ind  employed  unemployed  unemployed_rate  y_equiv  \\\n",
       "0    5  ...           -24.4    4827.7       486.8              9.5      0.0   \n",
       "1    5  ...           -24.4    4827.7       486.8              9.5      0.0   \n",
       "2    5  ...           -24.4    4827.7       486.8              9.5      0.0   \n",
       "3    5  ...           -24.4    4827.7       486.8              9.5      0.0   \n",
       "4    5  ...           -24.4    4827.7       486.8              9.5      0.0   \n",
       "\n",
       "  contact_missing poutcome_missing  job_missing education_missing  overdraft  \n",
       "0               1                0            0                 0        0.0  \n",
       "1               1                0            0                 0        0.0  \n",
       "2               1                0            0                 0        0.0  \n",
       "3               1                0            0                 1        0.0  \n",
       "4               1                0            1                 1        0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all categoric features numeric ! \n",
    "#cats\n",
    "#job --> hot encoding, marital as well and education as well ? \n",
    "#default,housing,load,contact yes=1,no=0, contact=unknown==0(i have another repreesntative)\n",
    "#month -> numerical\n",
    "#day_of_week -> \n",
    "#fix ranges where numeric variables exist! \n",
    "\n",
    "binary=['default','housing','loan','contact','poutcome']\n",
    "orig_binary=df[binary]\n",
    "\n",
    "df.loc[df['default']==\"yes\",'default']=1\n",
    "df.loc[df['default']==\"no\",'default']=0\n",
    "\n",
    "df.loc[df['housing']==\"yes\",'housing']=1\n",
    "df.loc[df['housing']==\"no\",'housing']=0\n",
    "\n",
    "df.loc[df['loan']==\"yes\",'loan']=1\n",
    "df.loc[df['loan']==\"no\",'loan']=0\n",
    "\n",
    "df.loc[df['contact']==\"cellular\",'contact']=1\n",
    "df.loc[(df['contact'] == \"telephone\") | (df['contact'] == \"unknown\"),'contact']=0 #we can cast unknowns as 0 now that we have a variable to indicate it ! \n",
    "\n",
    "df.loc[df['poutcome'] ==\"success\",'poutcome']=1\n",
    "df.loc[(df['poutcome'] == \"non_existant\") | (df['poutcome'] == \"failure\") | (df['poutcome'] == \"other\"),'poutcome']=0\n",
    "\n",
    "\n",
    "months = {month: index for index, month in enumerate(calendar.month_abbr) if month}\n",
    "months['Jan']\n",
    "for month in months:\n",
    "    #print(month.lower(),months[month])\n",
    "    df.loc[df['month']==month.lower(),'month']=months[month]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"before_hotencoding.csv\",\n",
    "          index=False,\n",
    "          encoding=\"utf-8\")\n",
    "\n",
    "df['balance']=df.balance.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>genre_encoded_dumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>7771</td>\n",
       "      <td>7201</td>\n",
       "      <td>570</td>\n",
       "      <td>0.073350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technician</td>\n",
       "      <td>6072</td>\n",
       "      <td>5392</td>\n",
       "      <td>680</td>\n",
       "      <td>0.111989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>management</td>\n",
       "      <td>7588</td>\n",
       "      <td>6548</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.137059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>1067</td>\n",
       "      <td>899</td>\n",
       "      <td>168</td>\n",
       "      <td>0.157451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retired</td>\n",
       "      <td>1831</td>\n",
       "      <td>1409</td>\n",
       "      <td>422</td>\n",
       "      <td>0.230475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>1182</td>\n",
       "      <td>1083</td>\n",
       "      <td>99</td>\n",
       "      <td>0.083756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>admin.</td>\n",
       "      <td>4152</td>\n",
       "      <td>3643</td>\n",
       "      <td>509</td>\n",
       "      <td>0.122592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>986</td>\n",
       "      <td>907</td>\n",
       "      <td>79</td>\n",
       "      <td>0.080122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>services</td>\n",
       "      <td>3272</td>\n",
       "      <td>2976</td>\n",
       "      <td>296</td>\n",
       "      <td>0.090465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>self-employed</td>\n",
       "      <td>1280</td>\n",
       "      <td>1125</td>\n",
       "      <td>155</td>\n",
       "      <td>0.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>student</td>\n",
       "      <td>734</td>\n",
       "      <td>532</td>\n",
       "      <td>202</td>\n",
       "      <td>0.275204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unknown</td>\n",
       "      <td>229</td>\n",
       "      <td>198</td>\n",
       "      <td>31</td>\n",
       "      <td>0.135371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category  count  target_0  target_1  genre_encoded_dumb\n",
       "0     blue-collar   7771      7201       570            0.073350\n",
       "1      technician   6072      5392       680            0.111989\n",
       "2      management   7588      6548      1040            0.137059\n",
       "3      unemployed   1067       899       168            0.157451\n",
       "4         retired   1831      1409       422            0.230475\n",
       "5    entrepreneur   1182      1083        99            0.083756\n",
       "6          admin.   4152      3643       509            0.122592\n",
       "7       housemaid    986       907        79            0.080122\n",
       "8        services   3272      2976       296            0.090465\n",
       "9   self-employed   1280      1125       155            0.121094\n",
       "10        student    734       532       202            0.275204\n",
       "11        unknown    229       198        31            0.135371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for high cardinality job according to how frequent a value appears, encode it .. BEFORE THIS STEP, SPLIT DATA FOR TRAINING AND TESTING AND ONLY USE TARGETS OF TRAINING DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns[df.columns!='y_equiv']], df['y_equiv'], test_size=0.2, random_state=11)\n",
    "\n",
    "#https://analyticsindiamag.com/a-complete-guide-to-categorical-data-encoding/\n",
    "#https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f1733a4c69\n",
    "categories = X_train.job.unique()#df['job'].unique()\n",
    "targets = y_train.astype('int32').unique()#df['y_equiv'].astype('int32').unique()\n",
    "cat_list = []\n",
    "for cat in categories:\n",
    "    aux_dict = {}\n",
    "    aux_dict['category'] = cat\n",
    "    aux_df = X_train[X_train['job'] == cat]\n",
    "    counts = df.loc[X_train[X_train['job'] == cat].index,'y_equiv'].value_counts()\n",
    "    aux_dict['count'] = sum(counts)\n",
    "    for t in targets:\n",
    "# #        print(t)\n",
    "        aux_dict['target_' + str(t)] = counts[t]\n",
    "    cat_list.append(aux_dict)\n",
    "cat_list = pd.DataFrame(cat_list)\n",
    "cat_list['genre_encoded_dumb'] = cat_list['target_1'] / cat_list['count']\n",
    "display(cat_list)\n",
    "orig_job=cat_list\n",
    "\n",
    "for cat in cat_list.category:\n",
    "    educ_equiv=cat_list.loc[cat_list['category']==cat,'genre_encoded_dumb'].tolist()[0]\n",
    "    #print(cat,educ_equiv)\n",
    "    df.loc[df['job']==cat,'job']=educ_equiv#.astype('float64')\n",
    "\n",
    "cat_list.to_csv(\"education_list.csv\",\n",
    "          index=False,\n",
    "          encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tertiary', 'secondary', 'unknown', 'primary']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #ordinal encoding for education\n",
    "orig_education=df['education']\n",
    "\n",
    "ordinal_educ=df.education.unique().tolist()\n",
    "ordinal_educ_encoded=[3,2,0,1]\n",
    "display(ordinal_educ)\n",
    " \n",
    "#for col in [\"education\"]:\n",
    "#    df[col]=LabelEncoder().fit_transform(df[col])\n",
    "#    print(LabelEncoder().fit(df[col]).classes_)\n",
    "#label encoder assigns ['tertiary', 'secondary', 'unknown', 'primary'] as [0:3] hence losing the ordinal idea \n",
    "ind=0\n",
    "for e in ordinal_educ:\n",
    "    df.loc[df['education']==e,'education']=ordinal_educ_encoded[ind]\n",
    "    ind=ind+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mairal=df.marital\n",
    "dum_df = pd.get_dummies(df['marital'], columns=[\"marital\"] )\n",
    "# merge with main df bridge_df on key values\n",
    "df = df.join(dum_df)\n",
    "df.drop(['marital'],axis=1,inplace=True)\n",
    "\n",
    "df.to_csv(\"before_hotencoding2.csv\",\n",
    "          index=False,\n",
    "          encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#nominal data hot encoding\n",
    "#for col in [\"day_of_week\",\"marital\"]:\n",
    "orig_dates=df[[\"day_of_week\",\"year\",\"month\"]]\n",
    "for col in [\"day_of_week\",\"year\",\"month\"]:    \n",
    "    #str(col+'_encoded')\n",
    "    days_enc=pd.DataFrame(OneHotEncoder().fit_transform(df[[col]]).toarray())\n",
    "    colname=[]\n",
    "    for day in range(len(days_enc.columns)):#.column:\n",
    "        #print(day)\n",
    "        colname.append(str(col)+str(day+1)) \n",
    "    \n",
    "    #display(colname)\n",
    "    df[colname] = days_enc\n",
    "\n",
    "\n",
    "df.drop(['day_of_week','year','month'],axis=1,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "df.to_csv(\"week9.csv\",\n",
    "          index=False,\n",
    "          encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# #binning of balance then label_encode\n",
    "# #assume5bgroups\n",
    "# bins_it=(X_train.balance.max()-X_train.balance.min())/5\n",
    "# bins=[]#[df.balance.min()]\n",
    "# for i in range(1,5):\n",
    "#     bins.append(bins_it*i+1)\n",
    "# bins.append(X_train.balance.max())\n",
    "# #bins=[bins_middle,df.balance.max()]\n",
    "# print(bins)\n",
    "# #orig_balance=df['balance']\n",
    "# #df['balance'] = pd.cut(df['balance'], bins=5, labels=['vlow','low','med','high','vhigh'])\n",
    "\n",
    "\n",
    "# #binning of balance then label_encode\n",
    "# #assume5bgroups\n",
    "# bins_it=(df.balance.max()-df.balance.min())/5\n",
    "# bins=[]#[df.balance.min()]\n",
    "# for i in range(1,5):\n",
    "#     bins.append(bins_it*i+1)\n",
    "# bins.append(df.balance.max())\n",
    "# #bins=[bins_middle,df.balance.max()]\n",
    "# print(bins)\n",
    "# #orig_balance=df['balance']\n",
    "# #df['balance'] = pd.cut(df['balance'], bins=5, labels=['vlow','low','med','high','vhigh'])\n",
    "# X_train.describe()\n",
    "\n",
    "\n",
    "\n",
    "# ####################################################### balance \n",
    "\n",
    "\n",
    "# df.loc[df[\"balance\"]<0,'balance']=0 #as if balancerepresent +ve balance only\n",
    "# #binning of balance then label_encode\n",
    "# #assume5bgroups\n",
    "# bins_it=(df.balance.max()-df.balance.min())/5\n",
    "# bins=[]#[df.balance.min()]\n",
    "# for i in range(1,5):\n",
    "#     bins.append(bins_it*i+1)\n",
    "\n",
    "# bins.append(df.balance.max())\n",
    "# #bins=[bins_middle,df.balance.max()]\n",
    "# bins\n",
    "# orig_balance=df['balance']\n",
    "# df['balance'] = pd.cut(df['balance'], bins=5, labels=['vlow','low','med','high','vhigh'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
